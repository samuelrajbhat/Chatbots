{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d44be31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value={'question': 'Do you approve the following output?', 'llm_output': 'This is generated output.'}, resumable=True, ns=['human_approval_node:863ed46a-1d24-1489-6015-bc8e69b33170'])]\n",
      "Approved path taken.\n",
      "{'llm_output': 'This is generated output.', '__interrupt__': [Interrupt(value={'question': 'Do you approve the following output?', 'llm_output': 'This is generated output.'}, resumable=True, ns=['human_approval_node:0e0b880a-ca7b-6158-f43f-64df0142ba45'])]}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Literal\n",
    "import uuid\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "class State(TypedDict):\n",
    "    llm_output: str\n",
    "    decison : str\n",
    "\n",
    "# Simulate an LLM output node\n",
    "def llm_call_stimualtion(state: State) -> State:\n",
    "    return {\"llm_output\": \"This is generated output.\"}\n",
    "\n",
    "# Human aporoval node\n",
    "\n",
    "def human_approval_node(state: State) -> Command[Literal[\"approved_node\", \"rejected_node\", \"ended_node\"]]:\n",
    "    decision = interrupt(\n",
    "        {\n",
    "             \"question\": \"Do you approve the following output?\",\n",
    "             \"llm_output\": state[\"llm_output\"]\n",
    "        }\n",
    "    )\n",
    "    if decision == 'approve':\n",
    "        return Command(goto=\"approved_node\", update={\"decision\": \"approved\"})\n",
    "    elif decision == 'reject':\n",
    "        return Command(goto=\"rejected_node\", update={\"decison\": \"rejected\"})\n",
    "    else :\n",
    "        return Command(goto=\"ended_node\", update={\"decison\": \"ended\"})\n",
    "\n",
    "# Next steps after approval\n",
    "\n",
    "def approved_node(state: State) -> State:\n",
    "    print(\"Approved path taken.\")\n",
    "    return state\n",
    "\n",
    "def rejected_node(state: State) -> State:\n",
    "    print(\"Rejected path taken. \")\n",
    "    return state\n",
    "\n",
    "def ended_node(state: State):\n",
    "    print (\"This is end node\")\n",
    "    # return (Command(goto=END, update={\"decision\": \"\"}))\n",
    "    return END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"llm_call_stimualtion\", llm_call_stimualtion)\n",
    "graph_builder.add_node(\"human_approval_node\", human_approval_node)\n",
    "graph_builder.add_node(\"approved_node\", approved_node)\n",
    "graph_builder.add_node(\"rejected_node\", rejected_node)\n",
    "graph_builder.add_node(\"ended_node\", ended_node)\n",
    "\n",
    "graph_builder.set_entry_point(\"llm_call_stimualtion\")\n",
    "graph_builder.add_edge(\"llm_call_stimualtion\", \"human_approval_node\")\n",
    "graph_builder.add_edge(\"approved_node\", \"human_approval_node\" )\n",
    "graph_builder.add_edge(\"rejected_node\", \"human_approval_node\" )\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer = memory)\n",
    "\n",
    "#pass a thread ID to the graph to run it.\n",
    "config = {\"configurable\": {\"thread_id\":uuid.uuid4()}}\n",
    "result = graph.invoke({},  config=config)\n",
    "print(result[\"__interrupt__\"])\n",
    "\n",
    "\n",
    "final_result = graph.invoke(Command(resume=\"approve\"), config=config)\n",
    "# print(graph.invoke(Command(resume=\"Edited Text\"), config=config))\n",
    "print(final_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d7f42e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected path taken. \n",
      "{'llm_output': 'This is generated output.', 'decison': 'rejected', '__interrupt__': [Interrupt(value={'question': 'Do you approve the following output?', 'llm_output': 'This is generated output.'}, resumable=True, ns=['human_approval_node:249f4ca3-3e46-f766-af5d-bc3dfb33b4ff'])]}\n"
     ]
    }
   ],
   "source": [
    "final_result = graph.invoke(Command(resume=\"reject\"), config=config)\n",
    "print (final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40230a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved path taken.\n",
      "{'llm_output': 'This is generated output.', 'decison': 'rejected', '__interrupt__': [Interrupt(value={'question': 'Do you approve the following output?', 'llm_output': 'This is generated output.'}, resumable=True, ns=['human_approval_node:dadafd95-f3f2-686d-2b00-0a0f200e9eb9'])]}\n"
     ]
    }
   ],
   "source": [
    "final_result = graph.invoke(Command(resume=\"approve\"), config=config)\n",
    "print (final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = graph.invoke(Command(resume=\"ended\"), config=config)\n",
    "print (final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6384e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "def human_approval(state: State) -> Command[Literal [\"some_node\", \"another_node\"]]:\n",
    "    is_approved = interrupt(\n",
    "        {\n",
    "            \"question\" : \"Is this correct? \",\n",
    "            \"llm_output\": state[\"llm_output\"]\n",
    "        }\n",
    "    )\n",
    "    if is_approved:\n",
    "        return Command(goto= \"some_node\")\n",
    "    else:\n",
    "        return Command(goto= \"another_node\")\n",
    "    \n",
    "# Adding this node in the  right edge into the  graph\n",
    "\n",
    "graph_builder.add_node(\"human_approval\", human_approval)\n",
    "graph = graph_builder.compile(checkpointer= checkpointer)\n",
    "\n",
    "# After runnning the graph and hitting the interrupt , this  graph will pause.\n",
    "# #Resume it  with either an approval or rejection.\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"some_id\"}}\n",
    "\n",
    "graph.invoke(Command(resume = True), config = thread_config)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
